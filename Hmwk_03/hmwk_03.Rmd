---
title: "Assignment 3"
author: "Reid Ginoza"
date: "2/23/2020"
output: pdf_document
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(reticulate)
use_python("/Users/macowner/my_venv/py38/bin/python")
```

# Simulation

First I will simulate one-dimensional Brownian motion using `python` following [@higham2001algorithmic].

```{python setup python}
from matplotlib import pyplot as plt
import numpy as np


def brownian_motion(end_time=1., num_tsteps=500):
    dt = (end_time - 0) / num_tsteps
    dw = np.sqrt(dt) * np.random.normal(size=num_tsteps+1)
    # Brownian motion must start at time 0 with value 0
    dw[0] = 0
    w = dw.cumsum()
    t = np.linspace(0, end_time, num=num_tsteps+1)  # not used in calculations
    assert len(w) == len(t), f'time and position arrays are not the same length. len(t) - len(w) = {len(t) - len(w)}'
    return t, w, dw
```

```{python constants}
END_TIME = 1.
NUM_TSTEPS = 500
N_TRIALS = 10
CONSISTENT = True
PLOTS = True
```

```{python simulation}
# space for simulation
```


# Analytical Problem
From [@evans2012introduction], Exercise (33.):
Show directly that \(I(t):=W^2(t) - t\) is a martingale.

(Hint: \(W^2(t) = (W(t)-W(s))^2 - W^2(s) + 2W(t)W(s)\).
Take the conditional expectation with respect to \(\mathcal{W}(s)\), the history of \(W(\cdot)\), and then condition with respect to the history of \(I(\cdot)\).)

## My Solution
To show that \(I(t)\) is a martingale, we want to show that \(I(s) = \mathrm{E}(I(t) \vert \mathcal{U}(s))\).

Following the hint about \(W^2\):
\[
I(t):=W^2(t) - t = (W(t)-W(s))^2 - W^2(s) + 2W(t)W(s) - t
\]

Now, let \(\mathcal{U}(s)\) be the history of the \(I(\cdot)\) until time \(s\), and \(\mathcal{W}(s)\) be the history of \(W(\cdot)\) until time \(s\).
\begin{align}
\mathrm{E}(I(t) \vert \mathcal{W}(s)) &= \mathrm{E}( (W(t)-W(s))^2 - W^2(s) + 2W(t)W(s) - t \vert \mathcal{W}(s))\\
&= \mathrm{E}( (W(t)-W(s))^2 \vert \mathcal{W}(s)) 
- \mathrm{E}( W^2(s) \vert \mathcal{W}(s))
+ \mathrm{E}( 2W(t)W(s) \vert \mathcal{W}(s))
- \mathrm{E}( t\vert \mathcal{W}(s))\\
&= \mathrm{Var}(W(t)-W(s) \vert \mathcal{W}(s))
    + \lvert\mathrm{E}(W(t)-W(s))\rvert^2
- W^2(s)
+ 2W(s)\mathrm{E}(W(t) \vert \mathcal{W}(s))
- t\\
&= \mathrm{Var}(W(t) \vert \mathcal{W}(s))
- W^2(s)
+ 2W^2(s)
- t\\
&= t
+ W^2(s)
- t\\
&= W^2(s)
\end{align}


# References